IR: 10, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1
Test Acc: 0.8002 +- 0.0038, BAcc: 0.7656 +- 0.0077, F1: 0.7666 +- 0.0069, Val Acc F1: 0.7680

IR: 10, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1
Test Acc: 0.7991 +- 0.0036, BAcc: 0.7629 +- 0.0075, F1: 0.7654 +- 0.0075, Val Acc F1: 0.7712

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1
Test Acc: 0.7977 +- 0.0044, BAcc: 0.7625 +- 0.0084, F1: 0.7645 +- 0.0080, Val Acc F1: 0.7709

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1
Test Acc: 0.7938 +- 0.0052, BAcc: 0.7592 +- 0.0092, F1: 0.7592 +- 0.0091, Val Acc F1: 0.7683

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1
Test Acc: 0.7985 +- 0.0025, BAcc: 0.7617 +- 0.0066, F1: 0.7637 +- 0.0057, Val Acc F1: 0.7703

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1
Test Acc: 0.7930 +- 0.0034, BAcc: 0.7526 +- 0.0065, F1: 0.7560 +- 0.0064, Val Acc F1: 0.7727

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1
Test Acc: 0.7962 +- 0.0030, BAcc: 0.7575 +- 0.0075, F1: 0.7619 +- 0.0066, Val Acc F1: 0.7720

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1
Test Acc: 0.7984 +- 0.0044, BAcc: 0.7566 +- 0.0059, F1: 0.7607 +- 0.0056, Val Acc F1: 0.7723

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 10, alpha: 0.1
Test Acc: 0.7926 +- 0.0038, BAcc: 0.7664 +- 0.0079, F1: 0.7613 +- 0.0073, Val Acc F1: 0.7692

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 30, alpha: 0.1
Test Acc: 0.7996 +- 0.0039, BAcc: 0.7664 +- 0.0077, F1: 0.7668 +- 0.0063, Val Acc F1: 0.7706

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05
Test Acc: 0.8045 +- 0.0027, BAcc: 0.7711 +- 0.0073, F1: 0.7739 +- 0.0063, Val Acc F1: 0.7749

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.15
Test Acc: 0.7959 +- 0.0042, BAcc: 0.7689 +- 0.0087, F1: 0.7648 +- 0.0085, Val Acc F1: 0.7691


//alpha0.05
IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05, lamda_schedule: none, lamda_rampup: 50
Test Acc: 0.8020 +- 0.0034, BAcc: 0.7709 +- 0.0077, F1: 0.7721 +- 0.0074, Val Acc F1: 0.7737

//alpha0.05 + 4lamda
IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05, lamda_schedule: linear, lamda_rampup: 50
Test Acc: 0.7944 +- 0.0037, BAcc: 0.7582 +- 0.0075, F1: 0.7592 +- 0.0067, Val Acc F1: 0.7684

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05, lamda_schedule: cosine, lamda_rampup: 50
Test Acc: 0.7990 +- 0.0033, BAcc: 0.7604 +- 0.0083, F1: 0.7641 +- 0.0081, Val Acc F1: 0.7748

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05, lamda_schedule: exp, lamda_rampup: 50
Test Acc: 0.8047 +- 0.0028, BAcc: 0.7651 +- 0.0058, F1: 0.7691 +- 0.0058, Val Acc F1: 0.7738

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05, lamda_schedule: step, lamda_rampup: 50
Test Acc: 0.7881 +- 0.0041, BAcc: 0.7521 +- 0.0073, F1: 0.7520 +- 0.0065, Val Acc F1: 0.7679

////alpha0.1 + 4lamda
IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: linear, lamda_rampup: 50
Test Acc: 0.8026 +- 0.0040, BAcc: 0.7685 +- 0.0083, F1: 0.7727 +- 0.0076, Val Acc F1: 0.7780

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: cosine, lamda_rampup: 50
Test Acc: 0.7980 +- 0.0033, BAcc: 0.7649 +- 0.0057, F1: 0.7666 +- 0.0058, Val Acc F1: 0.7715

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: exp, lamda_rampup: 50
Test Acc: 0.8030 +- 0.0052, BAcc: 0.7683 +- 0.0093, F1: 0.7726 +- 0.0092, Val Acc F1: 0.7748

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: step, lamda_rampup: 50
Test Acc: 0.7972 +- 0.0034, BAcc: 0.7534 +- 0.0063, F1: 0.7603 +- 0.0064, Val Acc F1: 0.7723

//动态alpha-lamda调度 alpha=0.05
IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05, lamda_schedule: none, lamda_rampup: 50
Test Acc: 0.8004 +- 0.0036, BAcc: 0.7672 +- 0.0080, F1: 0.7680 +- 0.0072, Val Acc F1: 0.7708

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05, lamda_schedule: linear, lamda_rampup: 50
Test Acc: 0.7937 +- 0.0041, BAcc: 0.7610 +- 0.0076, F1: 0.7595 +- 0.0076, Val Acc F1: 0.7676

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05, lamda_schedule: cosine, lamda_rampup: 50
Test Acc: 0.7924 +- 0.0056, BAcc: 0.7569 +- 0.0077, F1: 0.7591 +- 0.0089, Val Acc F1: 0.7741

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05, lamda_schedule: exp, lamda_rampup: 50
Test Acc: 0.7971 +- 0.0036, BAcc: 0.7617 +- 0.0079, F1: 0.7635 +- 0.0071, Val Acc F1: 0.7705

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05, lamda_schedule: step, lamda_rampup: 50
Test Acc: 0.7965 +- 0.0044, BAcc: 0.7604 +- 0.0067, F1: 0.7637 +- 0.0069, Val Acc F1: 0.7715

//动态alpha-lamda调度，alpha=0.1
IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: none, lamda_rampup: 50
Test Acc: 0.7967 +- 0.0034, BAcc: 0.7627 +- 0.0070, F1: 0.7664 +- 0.0068, Val Acc F1: 0.7711

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: linear, lamda_rampup: 50
Test Acc: 0.7977 +- 0.0037, BAcc: 0.7589 +- 0.0085, F1: 0.7663 +- 0.0076, Val Acc F1: 0.7784

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: cosine, lamda_rampup: 50
Test Acc: 0.7966 +- 0.0038, BAcc: 0.7588 +- 0.0086, F1: 0.7621 +- 0.0076, Val Acc F1: 0.7728

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: exp, lamda_rampup: 50
Test Acc: 0.8023 +- 0.0028, BAcc: 0.7670 +- 0.0083, F1: 0.7705 +- 0.0073, Val Acc F1: 0.7772

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: step, lamda_rampup: 50
Test Acc: 0.7966 +- 0.0033, BAcc: 0.7580 +- 0.0065, F1: 0.7646 +- 0.0063, Val Acc F1: 0.7722

//动态alpha-lamda调度，alpha=0.1 rampup = 100
IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: none, lamda_rampup: 100
Test Acc: 0.8000 +- 0.0037, BAcc: 0.7676 +- 0.0082, F1: 0.7668 +- 0.0070, Val Acc F1: 0.7743

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: linear, lamda_rampup: 100
Test Acc: 0.7932 +- 0.0037, BAcc: 0.7514 +- 0.0044, F1: 0.7582 +- 0.0055, Val Acc F1: 0.7758

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: cosine, lamda_rampup: 100
Test Acc: 0.7937 +- 0.0049, BAcc: 0.7558 +- 0.0071, F1: 0.7596 +- 0.0067, Val Acc F1: 0.7690

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: exp, lamda_rampup: 100
Test Acc: 0.7988 +- 0.0033, BAcc: 0.7591 +- 0.0062, F1: 0.7629 +- 0.0059, Val Acc F1: 0.7730

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: step, lamda_rampup: 100
Test Acc: 0.7954 +- 0.0035, BAcc: 0.7556 +- 0.0079, F1: 0.7615 +- 0.0069, Val Acc F1: 0.7731

////////////////////////////////////////
IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05, lamda_schedule: none, lamda_rampup: 50
Test Acc: 0.7978 +- 0.0046, BAcc: 0.7669 +- 0.0086, F1: 0.7669 +- 0.0084, Val Acc F1: 0.7709

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05, lamda_schedule: none, lamda_rampup: 50
Test Acc: 0.8028 +- 0.0029, BAcc: 0.7681 +- 0.0061, F1: 0.7696 +- 0.0067, Val Acc F1: 0.7739

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: none, lamda_rampup: 50
Test Acc: 0.7981 +- 0.0029, BAcc: 0.7585 +- 0.0064, F1: 0.7614 +- 0.0063, Val Acc F1: 0.7715

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.01, lamda_schedule: none, lamda_rampup: 50
Test Acc: 0.7809 +- 0.0046, BAcc: 0.7503 +- 0.0069, F1: 0.7467 +- 0.0070, Val Acc F1: 0.7573

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.03, lamda_schedule: none, lamda_rampup: 50
Test Acc: 0.7937 +- 0.0041, BAcc: 0.7577 +- 0.0080, F1: 0.7600 +- 0.0074, Val Acc F1: 0.7643

//////////////////////////////////////////
IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.05, lamda_schedule: none, lamda_rampup: 50
Test Acc: 0.8014 +- 0.0033, BAcc: 0.7712 +- 0.0080, F1: 0.7710 +- 0.0074, Val Acc F1: 0.7749

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.07, lamda_schedule: none, lamda_rampup: 50
Test Acc: 0.7965 +- 0.0055, BAcc: 0.7662 +- 0.0102, F1: 0.7663 +- 0.0093, Val Acc F1: 0.7680

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.1, lamda_schedule: none, lamda_rampup: 50
Test Acc: 0.8035 +- 0.0052, BAcc: 0.7683 +- 0.0104, F1: 0.7717 +- 0.0097, Val Acc F1: 0.7720

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.15, lamda_schedule: none, lamda_rampup: 50
Test Acc: 0.8016 +- 0.0031, BAcc: 0.7677 +- 0.0077, F1: 0.7704 +- 0.0067, Val Acc F1: 0.7825

IR: 10.0, net: Diff, n_layer: 2, feat_dim: 128, lr: 0.1, weight_decay: 0.005, dropout: 0.5 
            TAM: False, BAT: False, ENS: False, SHA: False, loss_type: bs, no_pseudo: False, label_per_class: 20, T: 20, alpha: 0.2, lamda_schedule: none, lamda_rampup: 50
Test Acc: 0.7926 +- 0.0034, BAcc: 0.7613 +- 0.0088, F1: 0.7614 +- 0.0080, Val Acc F1: 0.7695

